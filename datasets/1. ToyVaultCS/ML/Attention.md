В июне 2017 года восемь исследователей из Google Brain и Google Research опубликовали статью, которая за несколько лет перевернула всё здание обработки последовательностей. «Attention Is All You Need» (Vaswani et al., arXiv:1706.03762) стала манифестом новой архитектурной парадигмы — Transformer.

### Почему именно 2017-й стал переломным
К 2017 году индустрия достигла предела масштабирования рекуррентных сетей:
- Последовательная природа LSTM/GRU делала обучение медленным и дорогим
- Длинные зависимости всё ещё плохо захватывались
- Архитектуры типа Seq2Seq + attention (Bahdanau 2014, Luong 2015) уже показали, что attention мощнее рекурренции, но оставались гибридными

Transformer предложил радикальное решение: полностью отказаться от рекурренции и свёрток, заменив их исключительно механизмом внимания.

### Архитектурные новшества
1. **Scaled Dot-Product Attention** — математически простая и эффективная операция

$$ Attention(Q, K, V) = softmax(QK^T / √d_k) V $$

Масштабирование на √d_k решило проблему исчезающего градиента при больших размерностях.

2. **Multi-Head Attention** — восемь параллельных голов в базовой модели позволили одновременно смотреть на разные подпространства представлений.

3. **Positional Encoding** с фиксированными синусоидами — единственный элемент, несущий информацию о порядке, поскольку сам attention порядок-инвариантен.

4. **Полная параллелизация** — длина последовательности влияет только на память, а не на время вычислений.

### Экспериментальные результаты 2017 года
На задаче машинного перевода WMT 2014 English-German:
- Transformer (big) — 28.4 BLEU (новый абсолютный рекорд)
- Обучение в 8 раз быстрее лучших RNN- и CNN-архитектур того времени
- 65 М параметров в base-версии против сотен миллионов у конкурентов

### Наследие к 2025 году
Из одной статьи выросли почти все значимые языковые, мультимодальные и даже научные модели:
- [[BERT]] и вся эпоха pre-trained encoder’ов
- [[GPT]]-семейство и decoder-only архитектуры
- T5, BART, DeBERTa, ALBERT, RoBERTa
- Все современные диффузионные модели и большинство vision transformer’ов

Сегодня трудно назвать крупную модель, которая не использует хотя бы один блок Transformer. Статья собрала более 180 000 цитирований и продолжает оставаться самой цитируемой работой по компьютерным наукам XXI века.

См. также: [[Transformer]], [[BERT]], [[GPT-3]]